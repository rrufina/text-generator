{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "GPT3_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0LgK5_3HWT",
        "outputId": "8ed810e7-d35d-4ddb-b04e-2e856bd42030"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZtCTtrdZ21mK"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, GPT2Model\n",
        "from transformers import get_linear_schedule_with_warmup\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "phopRWoF21mM"
      },
      "source": [
        "data_list = set()\n",
        "with open('com.txt','r') as f:\n",
        "    text = f.read()\n",
        "    text  =text.split('\\n')\n",
        "    data_list.update(text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaDlYh5pEB92",
        "outputId": "f449fae6-2c4a-4b78-efa0-d69ad983c03c"
      },
      "source": [
        "print(len(data_list))\n",
        "count = 0.0\n",
        "max_len = 0\n",
        "for s in data_list:\n",
        "  lena = len(s.split())\n",
        "  count += lena\n",
        "  if lena > max_len:\n",
        "    max_len = lena\n",
        "print(count / len(data_list))\n",
        "print(max_len)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "668\n",
            "13.47754491017964\n",
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyntBPle21mM",
        "outputId": "14b926f3-2a63-4fa0-e9e8-39069200c4be"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2gWED_78PH_"
      },
      "source": [
        "max_length = 35\n",
        "\n",
        "class ComplDataset(Dataset):\n",
        "    def __init__(self, compl, tokenizer, length):\n",
        "        self.compliments = []\n",
        "\n",
        "        for sent in data_list:\n",
        "            encod_dic = tokenizer('<SOS> ' + sent + ' <EOS>', truncation=True, max_length=length,\n",
        "                                  padding='max_length')\n",
        "            self.compliments.append(torch.tensor(encod_dic['input_ids']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.compliments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.compliments[idx]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpI5GUgc8ulk",
        "outputId": "d0d96fa5-5296-4997-ef5e-5e7f35e71405"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<SOS>', eos_token='<EOS>', pad_token = '<EOS>')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrxfH3Pf9VXa"
      },
      "source": [
        "dataset = ComplDataset(data_list, tokenizer, max_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdcVN4qhDRjz"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_ids, val_ids = train_test_split(\n",
        "    np.arange(len(dataset)),\n",
        "    test_size=0.1,\n",
        "    shuffle=True)\n",
        "\n",
        "train = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "val = torch.utils.data.SubsetRandomSampler(val_ids)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, sampler=train)\n",
        "val_dataloader =  torch.utils.data.DataLoader(dataset, batch_size=1, sampler=val)\n",
        "\n",
        "train_size = len(train_ids)\n",
        "val_size = len(val_ids)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HevHNPhX21mO"
      },
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "# Used documentation: https://huggingface.co/transformers/model_doc/gpt2.html\n",
        "\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=5000, num_training_steps = -1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEXlCtay21mP",
        "outputId": "98fb36fa-2613-4949-d821-f421372dd8c7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "c = 0\n",
        "best = 100\n",
        "\n",
        "for epoch in range(10):\n",
        "    epoch_loss_train = 0\n",
        "    model.train()\n",
        "    for i, entity in enumerate(tqdm(train_dataloader)):\n",
        "        c += 1\n",
        "        input_ids = entity.to(device)\n",
        "\n",
        "        outputs = model(input_ids, labels = input_ids)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        epoch_loss_train += batch_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        model.zero_grad()\n",
        "\n",
        "        if (c % 100 == 0):\n",
        "          model.eval()\n",
        "          epoch_loss_val = 0\n",
        "\n",
        "          for entity in val_dataloader:\n",
        "              with torch.no_grad():\n",
        "                  input_ids = entity.to(device)\n",
        "                  outputs = model(input_ids, labels = input_ids)\n",
        "                  loss = outputs[0]\n",
        "              batch_loss = loss.item()\n",
        "              epoch_loss_val += batch_loss\n",
        "\n",
        "          av_val_loss = epoch_loss_val / val_size\n",
        "\n",
        "          if av_val_loss < best:\n",
        "            print('Average val loss: {}'.format(av_val_loss))\n",
        "            best = av_val_loss\n",
        "            torch.save(model.state_dict(), 'models/GPT2.h5')\n",
        "          \n",
        "          model.train()\n",
        "\n",
        "\n",
        "    print('Average train loss: {}'.format(epoch_loss_train / train_size))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 99/301 [00:17<00:35,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 45.77679829099285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 199/301 [00:37<00:17,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 37.255958386321566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 299/301 [00:57<00:00,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 13.897107022911754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:00<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 17.487877554584067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 98/301 [00:17<00:35,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 4.603687579952069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 198/301 [00:37<00:17,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 3.15096568883355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 298/301 [00:57<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 2.7454295967941853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:00<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 2.260743638243334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 97/301 [00:16<00:35,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 2.433997559903273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 197/301 [00:37<00:18,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 2.276442594492613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 297/301 [00:57<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 2.0934685922380702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:00<00:00,  4.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 1.296801243169534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 96/301 [00:16<00:35,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 2.0199313306096776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 196/301 [00:36<00:18,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.9166038187582102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 296/301 [00:57<00:00,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.8446971413804525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:00<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 1.023288653962029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 95/301 [00:16<00:35,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.7880815863609314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 195/301 [00:36<00:18,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.7606081993722205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 295/301 [00:56<00:01,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.7511682835087847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:00<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 0.9123176918450291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 94/301 [00:16<00:36,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.6810610272101503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 194/301 [00:36<00:18,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.6632352151087861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 294/301 [00:57<00:01,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.619646264990764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:01<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 0.8432074449026644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 193/301 [00:34<00:18,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.6171343820308572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 293/301 [00:54<00:01,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.6132736125988747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:59<00:00,  5.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 0.7802560542169308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 92/301 [00:15<00:36,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.5933099776061612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 192/301 [00:36<00:18,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.584849691213067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 292/301 [00:56<00:01,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.5277713492735108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:00<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 0.7427779349332642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 91/301 [00:15<00:36,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.508146572024075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 191/301 [00:35<00:19,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average val loss: 1.4954226546323122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:58<00:00,  5.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 0.7163445063914713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:56<00:00,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 0.6699844568025649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UL5Bh2dX21mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29984f29-6544-4b19-e3e8-75e0a7533577"
      },
      "source": [
        "state_dict = torch.load('models/GPT2.h5')\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "f9K1jhX621mQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1286ae03-a3d7-4326-9848-f9a0f8448524"
      },
      "source": [
        "model.eval()\n",
        "generated = torch.tensor(tokenizer.encode('<SOS>')).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length =35,\n",
        "                                top_p=0.8, \n",
        "                                bos_token = '<SOS>',\n",
        "                                eos_token = '<EOS>',\n",
        "                                num_return_sequences=5\n",
        "                                )\n",
        "\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True).replace('\\n',' ')))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257]], device='cuda:0')\n",
            "0:  that you have been with me since daybreak has been the greatest joy of my life \n",
            "\n",
            "\n",
            "1:  a moment of sunshine is enough for me to smile and to inspire you \n",
            "\n",
            "\n",
            "2:  if i say this word, i will not stop loving you and caring for you forever \n",
            "\n",
            "\n",
            "3:  that i am with you, it is an honor to be with you \n",
            "\n",
            "\n",
            "4:  in your heart, i feel like you are my guardian angel \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
