{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pmldl-project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDGnQ_OPzlUI",
        "outputId": "7a5eea12-9c24-422b-e3b5-bb734375761c"
      },
      "source": [
        "import numpy\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKDjrxbkz1Cs"
      },
      "source": [
        "import os, shutil\n",
        "data_list = []\n",
        "folder = '/content/drive/MyDrive/Study/ML/dataset'\n",
        "for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    with open(file_path, 'r') as f:\n",
        "        text = f.read()\n",
        "        data_list.append(text)\n",
        "data = \" \".join(data_list)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxwF72Yg2HsB"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD8PDzNIz2jJ"
      },
      "source": [
        "def tokenize_words(input):\n",
        "    # lowercase everything to standardize it\n",
        "    input = input.lower()\n",
        "\n",
        "    # instantiate the tokenizer\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(input)\n",
        "\n",
        "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
        "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "    return \" \".join(filtered)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioO1iLs5z4yD"
      },
      "source": [
        "# preprocess the input data, make tokens\n",
        "processed_inputs = tokenize_words(data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdToLE0Xz69u"
      },
      "source": [
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdqHyvuwz7-7",
        "outputId": "feb8e6d2-c162-40cc-89d5-96b1eca5bb0b"
      },
      "source": [
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print (\"Total number of characters:\", input_len)\n",
        "print (\"Total vocab:\", vocab_len)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 54049\n",
            "Total vocab: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lTICZqQz9Sl"
      },
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQTce4uZz-w5"
      },
      "source": [
        "# loop through inputs, start at the beginning and go until we hit\n",
        "# the final character we can create a sequence out of\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "    # Define input and output sequences\n",
        "    # Input is the current character plus desired sequence length\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "\n",
        "    # Out sequence is the initial character plus total sequence length\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "\n",
        "    # We now convert list of characters to integers based on\n",
        "    # previously and add the values to our lists\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4ZssB4o0AQi",
        "outputId": "f297f68f-9330-4f9e-900a-6414d09a4af3"
      },
      "source": [
        "n_patterns = len(x_data)\n",
        "print (\"Total Patterns:\", n_patterns)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 53949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTHqU1sG0B0c"
      },
      "source": [
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDvNkK950C_b"
      },
      "source": [
        "y = np_utils.to_categorical(y_data)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKjng2Vi0EiM"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAjNITCg0FuF"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz6ZcZqB336J",
        "outputId": "2bbbebf3-1d27-4a72-d669-19f27adaf2d6"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=256)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.6475\n",
            "Epoch 2/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.5960\n",
            "Epoch 3/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.5349\n",
            "Epoch 4/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.4777\n",
            "Epoch 5/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.4302\n",
            "Epoch 6/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.3878\n",
            "Epoch 7/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.3496\n",
            "Epoch 8/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.3143\n",
            "Epoch 9/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.2815\n",
            "Epoch 10/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.2530\n",
            "Epoch 11/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.2242\n",
            "Epoch 12/20\n",
            "211/211 [==============================] - 11s 53ms/step - loss: 2.1987\n",
            "Epoch 13/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.1701\n",
            "Epoch 14/20\n",
            "211/211 [==============================] - 11s 53ms/step - loss: 2.1514\n",
            "Epoch 15/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.1250\n",
            "Epoch 16/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.1122\n",
            "Epoch 17/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.0923\n",
            "Epoch 18/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.0762\n",
            "Epoch 19/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.0534\n",
            "Epoch 20/20\n",
            "211/211 [==============================] - 11s 54ms/step - loss: 2.0389\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3398aab050>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEC7vbze0KqT"
      },
      "source": [
        "num_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyej0DTw0MEb",
        "outputId": "59a68349-a1f9-46f1-88ae-d409db6e2367"
      },
      "source": [
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:\n",
            "\" friendship entire complete used showed yore little interest pupil brussels hold maintenance little i \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y1ak4qY0PZX",
        "outputId": "37577537-6328-459e-950a-7c8a99b8e030"
      },
      "source": [
        "for i in range(100):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(vocab_len)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = num_to_char[index]\n",
        "\n",
        "    sys.stdout.write(result)\n",
        "\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odeers see shall see shall see shall see shall see shall see shall see shall see shall see shall see"
          ]
        }
      ]
    }
  ]
}